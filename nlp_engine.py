import logging
import json
import os
import httpx
import asyncio
from typing import Dict, List, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class NlpEngine:
    """–ò–ò-–¥–≤–∏–∂–æ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∫–∞—Å–∫–∞–¥–∞ LLM"""
    
    def __init__(self):
        logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è NLP-–¥–≤–∏–∂–∫–∞...")
        
        # API –∫–ª—é—á OpenRouter
        self.api_key = os.getenv("OPENROUTER_API_TOKEN")
        if not self.api_key:
            raise ValueError("‚ùå OPENROUTER_API_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ö–∞—Å–∫–∞–¥ –º–æ–¥–µ–ª–µ–π (–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞)
        self.model_priority = [
            "google/gemini-2.0-flash-exp:free",
            "meta-llama/llama-3.3-70b-instruct:free",
            "qwen/qwen3-235b-a22b:free",
            "google/gemma-3-27b:free",
            "meta-llama/llama-3.2-3b-instruct:free"
        ]
        
        self.current_model_idx = 0
        self.model = self.model_priority[self.current_model_idx]
        self.api_url = "https://openrouter.ai/api/v1/chat/completions"
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.total_requests = 0
        self.successful_requests = 0
        self.model_switches = 0
        self.analysis_cache = {}
        
        logger.info(f"ü§ñ NLP-–¥–≤–∏–∂–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info(f"üß† –¢–µ–∫—É—â–∞—è –º–æ–¥–µ–ª—å: {self.model}")
        logger.info(f"üìã –í—Å–µ–≥–æ –º–æ–¥–µ–ª–µ–π –≤ –∫–∞—Å–∫–∞–¥–µ: {len(self.model_priority)}")
    
    def _switch_to_next_model(self):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å –≤ –∫–∞—Å–∫–∞–¥–µ"""
        old_model = self.model
        self.current_model_idx = (self.current_model_idx + 1) % len(self.model_priority)
        self.model = self.model_priority[self.current_model_idx]
        self.model_switches += 1
        
        logger.info(f"üîÑ –°–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏: {old_model} ‚Üí {self.model}")
        return self.model
    
    def _create_analysis_prompt(self, news_item: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –ø–æ–ª—è –Ω–æ–≤–æ—Å—Ç–∏
        title = news_item.get('title', '')
        description = news_item.get('description', '')
        content = news_item.get('content', '') or description
        source = news_item.get('source_name', news_item.get('source', 'Unknown'))
        
        prompt = f"""
        ===== –ê–ù–ê–õ–ò–ó –§–ò–ù–ê–ù–°–û–í–û–ô –ù–û–í–û–°–¢–ò =====
        
        üì∞ –ò–°–¢–û–ß–ù–ò–ö: {source}
        üè∑Ô∏è –ó–ê–ì–û–õ–û–í–û–ö: {title}
        
        üìù –¢–ï–ö–°–¢ –ù–û–í–û–°–¢–ò:
        {content[:1500]}
        
        ===== –ò–ù–°–¢–†–£–ö–¶–ò–Ø –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê =====
        
        –¢—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –ò–ò. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç—å –≤—ã—à–µ –∏ –æ—Ç–≤–µ—Ç—å –í –°–¢–†–û–ì–û–ú JSON –§–û–†–ú–ê–¢–ï.
        
        –ê–ù–ê–õ–ò–ó–ò–†–£–ô –°–õ–ï–î–£–Æ–©–ò–ï –ê–°–ü–ï–ö–¢–´:
        1. –ò–∑–≤–ª–µ–∫–∏ –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –∫–æ–º–ø–∞–Ω–∏–π –∏ –∏—Ö —Ç–∏–∫–µ—Ä–æ–≤ (–Ω–∞–ø—Ä–∏–º–µ—Ä: "–°–±–µ—Ä–±–∞–Ω–∫" ‚Üí SBER, "–ì–∞–∑–ø—Ä–æ–º" ‚Üí GAZP)
        2. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è:
           - earnings_report: –ö–≤–∞—Ä—Ç–∞–ª—å–Ω—ã–µ/–≥–æ–¥–æ–≤—ã–µ –æ—Ç—á–µ—Ç—ã
           - dividend: –î–∏–≤–∏–¥–µ–Ω–¥–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
           - merger_acquisition: –°–ª–∏—è–Ω–∏—è –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏—è
           - regulatory: –†–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è
           - geopolitical: –ì–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ —Å–æ–±—ã—Ç–∏—è
           - market_update: –û–±—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ –Ω–æ–≤–æ—Å—Ç–∏
           - corporate_action: –ö–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è
           - other: –î—Ä—É–≥–æ–µ
        3. –û—Ü–µ–Ω–∏ –≤–∞–∂–Ω–æ—Å—Ç—å (impact_score) –æ—Ç 1 –¥–æ 10:
           - 1-3: –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ
           - 4-6: –°—Ä–µ–¥–Ω–µ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–º–ø–∞–Ω–∏–∏
           - 7-8: –°–µ—Ä—å–µ–∑–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Å–µ–∫—Ç–æ—Ä
           - 9-10: –ö—Ä–∏—Ç–∏—á–µ—Å–∫–æ–µ –≤–ª–∏—è–Ω–∏–µ –Ω–∞ —Ä—ã–Ω–æ–∫
        4. –û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (relevance_score) –æ—Ç 1 –¥–æ 100:
           - 0-30: –ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞
           - 31-70: –°—Ä–µ–¥–Ω—è—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
           - 71-100: –í—ã—Å–æ–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å
        5. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å (sentiment):
           - positive: –ü–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å
           - negative: –ù–µ–≥–∞—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å
           - neutral: –ù–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å
           - mixed: –°–º–µ—à–∞–Ω–Ω–∞—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
        6. –û–ø—Ä–µ–¥–µ–ª–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç –≤–ª–∏—è–Ω–∏—è (horizon):
           - immediate: –í–ª–∏—è–Ω–∏–µ —Å–µ–≥–æ–¥–Ω—è/–∑–∞–≤—Ç—Ä–∞
           - short_term: –í–ª–∏—è–Ω–∏–µ –≤ —Ç–µ—á–µ–Ω–∏–µ –Ω–µ–¥–µ–ª–∏
           - medium_term: –í–ª–∏—è–Ω–∏–µ –≤ —Ç–µ—á–µ–Ω–∏–µ –º–µ—Å—è—Ü–∞
           - long_term: –î–æ–ª–≥–æ—Å—Ä–æ—á–Ω–æ–µ –≤–ª–∏—è–Ω–∏–µ
        7. –°–æ—Å—Ç–∞–≤—å –∫—Ä–∞—Ç–∫—É—é —Å—É—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
        
        –í–û–ó–í–†–ê–©–ê–ô –¢–û–õ–¨–ö–û JSON –í –°–õ–ï–î–£–Æ–©–ï–ú –§–û–†–ú–ê–¢–ï:
        {{
            "analysis": {{
                "tickers": ["TICKER1", "TICKER2"],
                "event_type": "—Ç–∏–ø_—Å–æ–±—ã—Ç–∏—è",
                "impact_score": —á–∏—Å–ª–æ_–æ—Ç_1_–¥–æ_10,
                "relevance_score": —á–∏—Å–ª–æ_–æ—Ç_1_–¥–æ_100,
                "sentiment": "—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å",
                "horizon": "–≥–æ—Ä–∏–∑–æ–Ω—Ç",
                "summary": "–∫—Ä–∞—Ç–∫–∞—è —Å—É—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
            }}
        }}
        
        –¢–û–õ–¨–ö–û JSON, –ë–ï–ó –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê!
        """
        
        return prompt
    
    async def analyze_news(self, news_item: Dict) -> Optional[Dict]:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é –ò–ò"""
        
        self.total_requests += 1
        request_id = self.total_requests
        
        logger.info(f"üß† –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ #{request_id}: {news_item.get('title', '')[:50]}...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_key = f"{news_item.get('title', '')[:50]}_{news_item.get('source', '')}"
        if cache_key in self.analysis_cache:
            logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
            return self.analysis_cache[cache_key]
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö
        max_retries = min(3, len(self.model_priority))
        last_error = None
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üì® –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries} —Å –º–æ–¥–µ–ª—å—é: {self.model}")
                
                prompt = self._create_analysis_prompt(news_item)
                
                async with httpx.AsyncClient(timeout=30.0) as client:
                    response = await client.post(
                        url=self.api_url,
                        headers={
                            "Authorization": f"Bearer {self.api_key}",
                            "Content-Type": "application/json",
                            "HTTP-Referer": "https://github.com",
                            "X-Title": "News NLP Trading AI"
                        },
                        json={
                            "model": self.model,
                            "messages": [
                                {
                                    "role": "system",
                                    "content": "–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –ò–ò. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç–∏ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–π —Å—Ç—Ä–æ–≥–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ. –ù–∏–∫–∞–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞!"
                                },
                                {"role": "user", "content": prompt}
                            ],
                            "temperature": 0.1,
                            "max_tokens": 800
                        }
                    )
                
                logger.info(f"üì• –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                
                if response.status_code == 200:
                    result = response.json()
                    ai_response = result["choices"][0]["message"]["content"]
                    
                    self.successful_requests += 1
                    
                    # –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞
                    analysis_result = self._parse_ai_response(ai_response, news_item)
                    
                    if analysis_result:
                        # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                        self.analysis_cache[cache_key] = analysis_result
                        if len(self.analysis_cache) > 50:
                            oldest = next(iter(self.analysis_cache))
                            del self.analysis_cache[oldest]
                        
                        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏")
                        return analysis_result
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç –ò–ò")
                        last_error = "Parse error"
                        
                elif response.status_code in [400, 404, 429]:
                    # –ü—Ä–æ–±–ª–µ–º–∞ —Å –º–æ–¥–µ–ª—å—é –∏–ª–∏ rate limit
                    error_data = response.json()
                    error_msg = error_data.get('error', {}).get('message', 'Unknown error')
                    
                    logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ {self.model}: {error_msg[:100]}")
                    
                    if attempt < max_retries - 1:
                        # –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–µ–π –ø–æ–ø—ã—Ç–∫–æ–π
                        next_model = self._switch_to_next_model()
                        logger.info(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ 2 —Å–µ–∫ –ø–µ—Ä–µ–¥ –º–æ–¥–µ–ª—å—é {next_model}...")
                        await asyncio.sleep(2)
                        continue
                    else:
                        last_error = f"–í—Å–µ –º–æ–¥–µ–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: {error_msg}"
                        break
                
                else:
                    last_error = f"HTTP {response.status_code}"
                    break
                    
            except httpx.TimeoutException:
                last_error = "–¢–∞–π–º–∞—É—Ç 30—Å"
                logger.error(f"‚è∞ –¢–∞–π–º–∞—É—Ç –Ω–∞ –º–æ–¥–µ–ª–∏ {self.model}")
                if attempt < max_retries - 1:
                    self._switch_to_next_model()
                    await asyncio.sleep(3)
                    continue
                break
                
            except Exception as e:
                last_error = str(e)
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:100]}")
                break
        
        if last_error:
            logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∞–Ω–∞–ª–∏–∑–∞ failed: {last_error}")
        
        return None
    
    def _parse_ai_response(self, response: str, news_item: Dict) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ò–ò"""
        try:
            # –ò—â–µ–º JSON –≤ –æ—Ç–≤–µ—Ç–µ
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning(f"‚ö†Ô∏è –ò–ò –Ω–µ –≤–µ—Ä–Ω—É–ª JSON: {response[:100]}...")
                return None
            
            json_str = response[start_idx:end_idx]
            data = json.loads(json_str)
            
            analysis_data = data.get("analysis", {})
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_fields = ['tickers', 'event_type', 'impact_score', 'relevance_score']
            if not all(field in analysis_data for field in required_fields):
                logger.warning("‚ö†Ô∏è –í –æ—Ç–≤–µ—Ç–µ –ò–ò –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è")
                return None
            
            # –°–æ–∑–¥–∞–µ–º –ø–æ–ª–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            result = {
                'news_id': news_item.get('id', ''),
                'news_title': news_item.get('title', ''),
                'news_source': news_item.get('source', ''),
                'news_url': news_item.get('url', ''),
                'analysis_timestamp': datetime.now().isoformat(),
                
                # –ê–Ω–∞–ª–∏–∑ –ò–ò
                'tickers': analysis_data.get('tickers', []),
                'event_type': analysis_data.get('event_type', 'other'),
                'impact_score': int(analysis_data.get('impact_score', 1)),
                'relevance_score': int(analysis_data.get('relevance_score', 30)),
                'sentiment': analysis_data.get('sentiment', 'neutral'),
                'horizon': analysis_data.get('horizon', 'short_term'),
                'summary': analysis_data.get('summary', ''),
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                'ai_model': self.model,
                'confidence': min(1.0, analysis_data.get('relevance_score', 30) / 100.0)
            }
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            tickers_str = ', '.join(result['tickers']) if result['tickers'] else '–ù–ï–¢ –¢–ò–ö–ï–†–û–í'
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑: {tickers_str} | Impact: {result['impact_score']}/10 | Relevance: {result['relevance_score']}/100")
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"‚ùå –ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç –ò–ò: {str(e)[:50]}")
            return None
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –æ—Ç–≤–µ—Ç–∞ –ò–ò: {str(e)[:50]}")
            return None
    
    def get_current_model(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–π –∞–∫—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        return self.model
    
    def get_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã NLP-–¥–≤–∏–∂–∫–∞"""
        return {
            'total_requests': self.total_requests,
            'successful_requests': self.successful_requests,
            'success_rate': (self.successful_requests / self.total_requests * 100) if self.total_requests > 0 else 0,
            'current_model': self.model,
            'model_switches': self.model_switches,
            'cache_size': len(self.analysis_cache)
        }

# signal_pipeline.py - –ì–ò–ë–†–ò–î–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù –° GIGACHAT –ò –¢–ï–•–ù–ò–ß–ï–°–ö–ò–ú –ê–ù–ê–õ–ò–ó–û–ú
import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Optional
import hashlib

logger = logging.getLogger(__name__)

class SignalPipeline:
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å GigaChat –∏ –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º –∞–Ω–∞–ª–∏–∑–æ–º"""
    
    def __init__(self, nlp_engine, finam_verifier, risk_manager, 
                 enhanced_analyzer, news_prefilter, technical_strategy=None):
        self.nlp_engine = nlp_engine
        self.finam_verifier = finam_verifier
        self.risk_manager = risk_manager
        self.enhanced_analyzer = enhanced_analyzer
        self.news_prefilter = news_prefilter
        self.technical_strategy = technical_strategy
        
        # –ö—ç—à –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        self.news_cache = {}
        self.technical_cache = {}
        self.cache_ttl = 300  # 5 –º–∏–Ω—É—Ç
        
        self.stats = {
            'total_news': 0,
            'total_technical_scans': 0,
            'filtered_news': 0,
            'gigachat_requests': 0,
            'gigachat_success': 0,
            'technical_signals': 0,
            'verification_passed': 0,
            'signals_generated': 0,
            'hybrid_signals': 0,
            'pipeline_start': datetime.now().isoformat()
        }
        
        logger.info("üöÄ –ì–∏–±—Ä–∏–¥–Ω—ã–π SignalPipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        logger.info("   –≠—Ç–∞–ø—ã: PreFilter ‚Üí GigaChat/Technical ‚Üí Finam ‚Üí RiskManager")
        logger.info(f"   –¢–µ—Ö. –∞–Ω–∞–ª–∏–∑: {'‚úÖ' if technical_strategy else '‚ùå'}")
    
    async def process_news_batch(self, news_items):
        fresh_news = []
        for news in news_items:
            news_id = news.get('id') or hash(news.get('title', ''))
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –µ—Å–ª–∏ —É–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª–∏ –≤ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 4 —á–∞—Å–∞
            if news_id in self.processed_news_cache:
                if time.time() - self.processed_news_cache[news_id] < 14400:  # 4 —á–∞—Å–∞
                    continue
            
            fresh_news.append(news)
            self.processed_news_cache[news_id] = time.time()
        
        logger.info(f"üìä –ì–∏–±—Ä–∏–¥–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π...")
        
        signals = []
        
        # 1. –ü–ê–†–ê–õ–õ–ï–õ–¨–ù–û: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)
        technical_signals = []
        if self.technical_strategy:
            try:
                self.stats['total_technical_scans'] += 1
                tech_signals = await self.technical_strategy.scan_for_signals()
                self.stats['technical_signals'] += len(tech_signals)
                technical_signals = tech_signals
                logger.info(f"üìà –¢–µ—Ö. –∞–Ω–∞–ª–∏–∑: {len(tech_signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:100]}")
        
        # 2. –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        news_signals = []
        processed = 0
        
        for news_item in news_list:
            try:
                signal = await self._process_single_news(news_item)
                if signal:
                    news_signals.append(signal)
                
                processed += 1
                
                # –ü–∞—É–∑–∞ –∫–∞–∂–¥—ã–µ 5 –Ω–æ–≤–æ—Å—Ç–µ–π
                if processed % 5 == 0:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {str(e)[:100]}")
                continue
        
        # 3. –û–ë–™–ï–î–ò–ù–ï–ù–ò–ï —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ –¥–≤—É—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        all_signals = news_signals + technical_signals
        self.stats['hybrid_signals'] = len(all_signals)
        
        # 4. –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —á–µ—Ä–µ–∑ RiskManager
        verified_signals = []
        current_prices = {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç–∏–∫–µ—Ä—ã –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ü–µ–Ω
        all_tickers = list(set(signal.get('ticker') for signal in all_signals if signal.get('ticker')))
        
        if all_tickers:
            logger.info(f"üí∞ –ü–æ–ª—É—á–µ–Ω–∏–µ —Ü–µ–Ω –¥–ª—è {len(all_tickers)} —Ç–∏–∫–µ—Ä–æ–≤...")
            current_prices = await self.finam_verifier.get_current_prices(all_tickers)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–∂–¥–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ RiskManager
        for signal in all_signals:
            try:
                ticker = signal.get('ticker')
                if not ticker:
                    continue
                    
                # –ü–æ–ª—É—á–∞–µ–º —Ü–µ–Ω—É –¥–ª—è —Ç–∏–∫–µ—Ä–∞
                if ticker not in current_prices:
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ü–µ–Ω—É –æ—Ç–¥–µ–ª—å–Ω–æ
                    price = await self.finam_verifier._get_price_from_finam(ticker)
                    if price:
                        current_prices[ticker] = price
                    else:
                        logger.warning(f"‚ö†Ô∏è –ù–µ—Ç —Ü–µ–Ω—ã –¥–ª—è {ticker}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–∏–≥–Ω–∞–ª")
                        continue
                
                # –î–ª—è –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –Ω—É–∂–Ω–∞ –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è
                if signal.get('ai_provider') in ['gigachat', 'enhanced']:
                    # –°–æ–∑–¥–∞—ë–º —É–ø—Ä–æ—â—ë–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏
                    analysis_for_verification = {
                        'tickers': [ticker],
                        'sentiment': signal.get('sentiment', 'neutral'),
                        'impact_score': signal.get('impact_score', 5),
                        'confidence': signal.get('confidence', 0.5),
                        'event_type': signal.get('event_type', 'ai_analyzed'),
                        'ai_provider': signal.get('ai_provider', 'gigachat')
                    }
                    
                    verification = await self.finam_verifier.verify_signal(analysis_for_verification)
                    
                    if not verification.get('valid'):
                        logger.debug(f"   ‚ùå Finam –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—è –Ω–µ –ø—Ä–æ–π–¥–µ–Ω–∞ –¥–ª—è {ticker}")
                        continue
                    
                    self.stats['verification_passed'] += 1
                    
                    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞ —á–µ—Ä–µ–∑ RiskManager
                    risk_signal = self.risk_manager.prepare_signal(
                        analysis=analysis_for_verification,
                        verification=verification,
                        current_prices={ticker: current_prices[ticker]}
                    )
                    
                    if risk_signal:
                        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Å–∏–≥–Ω–∞–ª–∞
                        risk_signal.update({
                            'original_reason': signal.get('reason'),
                            'pipeline_version': 'hybrid_v2',
                            'news_hash': signal.get('news_hash') if 'news_hash' in signal else self._create_news_hash(signal),
                            'processing_timestamp': datetime.now().isoformat(),
                            'nlp_provider': signal.get('ai_provider', 'unknown'),
                            'verification_source': 'finam'
                        })
                        verified_signals.append(risk_signal)
                        logger.info(f"‚úÖ –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω: {risk_signal['action']} {ticker}")
                
                # –î–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ —É–ø—Ä–æ—â—ë–Ω–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
                elif signal.get('ai_provider') == 'technical':
                    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Å–∏–≥–Ω–∞–ª—ã —É–∂–µ —Å–æ–¥–µ—Ä–∂–∞—Ç action –∏ –ª–æ–≥–∏–∫—É
                    analysis_for_risk = {
                        'tickers': [ticker],
                        'sentiment': signal.get('sentiment', 'neutral'),
                        'impact_score': signal.get('impact_score', 5),
                        'confidence': signal.get('confidence', 0.5),
                        'event_type': signal.get('event_type', 'technical'),
                        'ai_provider': 'technical',
                        'action': signal.get('action'),  # –í–∞–∂–Ω–æ: –ø–µ—Ä–µ–¥–∞—ë–º —É–∂–µ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω–Ω–æ–µ –¥–µ–π—Å—Ç–≤–∏–µ
                        'summary': signal.get('reason', '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª')
                    }
                    
                    # –°–æ–∑–¥–∞—ë–º —É–ø—Ä–æ—â—ë–Ω–Ω—É—é –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é
                    verification = {
                        'valid': True,
                        'reason': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Å–∏–≥–Ω–∞–ª',
                        'tickers': [ticker],
                        'primary_ticker': ticker,
                        'primary_price': current_prices[ticker]
                    }
                    
                    risk_signal = self.risk_manager.prepare_signal(
                        analysis=analysis_for_risk,
                        verification=verification,
                        current_prices={ticker: current_prices[ticker]}
                    )
                    
                    if risk_signal:
                        verified_signals.append(risk_signal)
                        logger.info(f"üìà –¢–µ—Ö. —Å–∏–≥–Ω–∞–ª –ø—Ä–∏–Ω—è—Ç: {risk_signal['action']} {ticker}")
                        
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–∏–≥–Ω–∞–ª–∞ {signal.get('ticker', 'unknown')}: {str(e)[:100]}")
                continue
        
        self.stats['signals_generated'] += len(verified_signals)
        
        logger.info(f"üìä –ò—Ç–æ–≥–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏:")
        logger.info(f"   üì∞ –ù–æ–≤–æ—Å—Ç–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {len(news_signals)}")
        logger.info(f"   üìà –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö —Å–∏–≥–Ω–∞–ª–æ–≤: {len(technical_signals)}")
        logger.info(f"   ‚úÖ –í–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–æ: {len(verified_signals)}")
        logger.info(f"   üí∞ –ü–æ–ª—É—á–µ–Ω–æ —Ü–µ–Ω: {len(current_prices)}")
        
        return verified_signals
    
    async def _process_single_news(self, news_item: Dict) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # 1. –ö–≠–®–ò–†–û–í–ê–ù–ò–ï (–ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π)
        news_hash = self._create_news_hash(news_item)
        if news_hash in self.news_cache:
            cache_time, cache_result = self.news_cache[news_hash]
            if (datetime.now().timestamp() - cache_time) < self.cache_ttl:
                if cache_result:
                    logger.debug(f"üîÑ –ö—ç—à-–ø–æ–ø–∞–¥–∞–Ω–∏–µ: {news_item.get('title', '')[:50]}")
                    return cache_result
                return None
        
        # 2. –ü–†–ï-–§–ò–õ–¨–¢–†–ê–¶–ò–Ø
        if not self.news_prefilter.is_tradable(news_item):
            self.stats['filtered_news'] += 1
            logger.debug(f"   ‚ùå PreFilter: {news_item.get('title', '')[:50]}")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –∫–∞–∫ "–Ω–µ —Ç–æ—Ä–≥—É–µ–º—ã–π"
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        # 3. –£–°–ò–õ–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó (–µ—Å–ª–∏ GigaChat –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω)
        enhanced_analysis = None
        if not self.nlp_engine.enabled:
            logger.debug(f"   üîß EnhancedAnalyzer: {news_item.get('title', '')[:50]}")
            enhanced_analysis = self.enhanced_analyzer.analyze_news(news_item)
            
            if not enhanced_analysis or not enhanced_analysis.get('tickers'):
                logger.debug(f"   ‚ùå Enhanced: –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ç–∏–∫–µ—Ä—ã")
                self.news_cache[news_hash] = (datetime.now().timestamp(), None)
                return None
            
            # –°–æ–∑–¥–∞—ë–º —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ enhanced –∞–Ω–∞–ª–∏–∑–∞
            signal = {
                'news_hash': news_hash,
                'ticker': enhanced_analysis['tickers'][0] if enhanced_analysis['tickers'] else None,
                'tickers': enhanced_analysis['tickers'],
                'sentiment': enhanced_analysis['sentiment'],
                'impact_score': enhanced_analysis['impact_score'],
                'confidence': enhanced_analysis['confidence'],
                'event_type': enhanced_analysis['event_type'],
                'reason': enhanced_analysis['summary'],
                'ai_provider': 'enhanced',
                'news_id': news_item.get('id', ''),
                'news_title': news_item.get('title', '')[:100],
                'timestamp': datetime.now().isoformat()
            }
            
            if signal['ticker']:
                self.news_cache[news_hash] = (datetime.now().timestamp(), signal)
                logger.debug(f"‚úÖ Enhanced —Å–∏–≥–Ω–∞–ª: {signal['ticker']} ({signal['sentiment']})")
                return signal
            return None
        
        # 4. GIGACHAT –ê–ù–ê–õ–ò–ó (–æ—Å–Ω–æ–≤–Ω–æ–π)
        self.stats['gigachat_requests'] += 1
        logger.debug(f"   üì° GigaChat: {news_item.get('title', '')[:60]}")
        
        nlp_analysis = await self.nlp_engine.analyze_news(news_item)
        
        if not nlp_analysis:
            logger.debug(f"   ‚ùå GigaChat –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª")
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        self.stats['gigachat_success'] += 1
        
        # –ï—Å–ª–∏ GigaChat —Å–∫–∞–∑–∞–ª "–Ω–µ —Ç–æ—Ä–≥—É–µ–º—ã–π"
        if not nlp_analysis.get('is_tradable', True):
            logger.debug(f"   ‚ö†Ô∏è GigaChat: –Ω–µ —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª")
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ç–∏–∫–µ—Ä—ã
        if not nlp_analysis.get('tickers'):
            logger.debug(f"   ‚ö†Ô∏è GigaChat: –Ω–µ—Ç —Ç–∏–∫–µ—Ä–æ–≤ –≤ –æ—Ç–≤–µ—Ç–µ")
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        # –°–æ–∑–¥–∞—ë–º —Å–∏–≥–Ω–∞–ª –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ GigaChat
        signal = {
            'news_hash': news_hash,
            'ticker': nlp_analysis['tickers'][0] if nlp_analysis['tickers'] else None,
            'tickers': nlp_analysis['tickers'],
            'sentiment': nlp_analysis['sentiment'],
            'impact_score': nlp_analysis['impact_score'],
            'confidence': nlp_analysis['confidence'],
            'event_type': nlp_analysis.get('event_type', 'ai_analyzed'),
            'reason': nlp_analysis.get('summary', '–ê–Ω–∞–ª–∏–∑ GigaChat'),
            'ai_provider': 'gigachat',
            'news_id': news_item.get('id', ''),
            'news_title': nlp_analysis.get('news_title', '')[:100],
            'timestamp': datetime.now().isoformat()
        }
        
        if signal['ticker']:
            self.news_cache[news_hash] = (datetime.now().timestamp(), signal)
            logger.debug(f"‚úÖ GigaChat —Å–∏–≥–Ω–∞–ª: {signal['ticker']} (impact={signal['impact_score']})")
            return signal
        
        return None
    
    def _create_news_hash(self, news_item: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ö—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        title = news_item.get('title', '')
        content = news_item.get('content', '') or news_item.get('description', '')
        source = news_item.get('source', '')
        
        text = f"{title[:100]}|{content[:200]}|{source}"
        return hashlib.md5(text.encode()).hexdigest()[:16]
    
    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ –ø–∞–π–ø–ª–∞–π–Ω–∞"""
        total_news = self.stats['total_news']
        gigachat_req = self.stats['gigachat_requests']
        gigachat_succ = self.stats['gigachat_success']
        tech_signals = self.stats['technical_signals']
        signals = self.stats['signals_generated']
        hybrid = self.stats['hybrid_signals']
        
        if total_news > 0:
            filter_rate = (self.stats['filtered_news'] / total_news) * 100
            if gigachat_req > 0:
                gigachat_success_rate = (gigachat_succ / gigachat_req) * 100
            else:
                gigachat_success_rate = 0
            signal_rate = (signals / total_news) * 100 if total_news > 0 else 0
            hybrid_rate = (hybrid / max(1, total_news + self.stats['total_technical_scans'])) * 100
        else:
            filter_rate = gigachat_success_rate = signal_rate = hybrid_rate = 0
        
        return {
            **self.stats,
            'filter_rate_percent': round(filter_rate, 1),
            'gigachat_success_rate': round(gigachat_success_rate, 1),
            'signal_rate_percent': round(signal_rate, 1),
            'hybrid_rate_percent': round(hybrid_rate, 1),
            'news_cache_size': len(self.news_cache),
            'technical_cache_size': len(self.technical_cache),
            'current_time': datetime.now().isoformat(),
            'processing_mode': 'hybrid_parallel' if self.technical_strategy else 'gigachat_sequential',
            'has_technical': bool(self.technical_strategy)
        }
    
    async def run_continuous_hybrid_scan(self, news_interval: int = 300, tech_interval: int = 60):
        """–ù–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–µ –≥–∏–±—Ä–∏–¥–Ω–æ–µ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ"""
        logger.info(f"üîÑ –ó–∞–ø—É—Å–∫ –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è...")
        logger.info(f"   –ù–æ–≤–æ—Å—Ç–∏: –∫–∞–∂–¥—ã–µ {news_interval} —Å–µ–∫, –¢–µ—Ö. –∞–Ω–∞–ª–∏–∑: –∫–∞–∂–¥—ã–µ {tech_interval} —Å–µ–∫")
        
        async def news_scan():
            while True:
                try:
                    logger.debug("üì∞ –ó–∞–ø—É—Å–∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–æ–≤–æ—Å—Ç–µ–π...")
                    news = await self.nlp_engine.news_fetcher.fetch_all_news() if hasattr(self.nlp_engine, 'news_fetcher') else []
                    if news:
                        signals = await self.process_news_batch(news[:10])  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
                        if signals:
                            logger.info(f"üìä –ù–æ–≤–æ—Å—Ç–Ω–æ–π —Å–∫–∞–Ω–∏–Ω–≥: {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
                    await asyncio.sleep(news_interval)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –Ω–æ–≤–æ—Å—Ç–Ω–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)[:100]}")
                    await asyncio.sleep(news_interval)
        
        async def technical_scan():
            while True:
                try:
                    if self.technical_strategy:
                        logger.debug("üìà –ó–∞–ø—É—Å–∫ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è...")
                        signals = await self.technical_strategy.scan_for_signals()
                        if signals:
                            logger.info(f"üìä –¢–µ—Ö. —Å–∫–∞–Ω–∏–Ω–≥: {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤")
                    await asyncio.sleep(tech_interval)
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)[:100]}")
                    await asyncio.sleep(tech_interval)
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
        await asyncio.gather(
            news_scan(),
            technical_scan()
        )

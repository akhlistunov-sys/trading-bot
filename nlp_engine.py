import logging
import json
import os
import asyncio
from datetime import datetime
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)

class NlpEngine:
    """–ì–∏–±—Ä–∏–¥–Ω—ã–π –ò–ò-–¥–≤–∏–∂–æ–∫ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π GigaChat –∏ OpenRouter"""
    
    def __init__(self):
        logger.info("üîß –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≥–∏–±—Ä–∏–¥–Ω–æ–≥–æ NLP-–¥–≤–∏–∂–∫–∞...")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
        self.gigachat_auth = GigaChatAuth()  # –î–æ–±–∞–≤—å—Ç–µ —ç—Ç—É —Å—Ç—Ä–æ–∫—É
        self.providers = {
            'gigachat': {
    'url': 'https://gigachat.devices.sberbank.ru/api/v1/chat/completions',
    'client_id': os.getenv('GIGACHAT_CLIENT_ID'),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º Client ID –≤–º–µ—Å—Ç–æ —Ç–æ–∫–µ–Ω–∞
    'scope': os.getenv('GIGACHAT_SCOPE', 'GIGACHAT_API_PERS'),
    'models': ['GigaChat', 'GigaChat-Pro'],
    'enabled': bool(os.getenv('GIGACHAT_CLIENT_ID')),  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ Client ID
    'priority': 1,
    'auth': self.gigachat_auth  # –î–æ–±–∞–≤–ª—è–µ–º —Å—Å—ã–ª–∫—É –Ω–∞ auth –æ–±—ä–µ–∫—Ç
}
            'openrouter': {
                'url': 'https://openrouter.ai/api/v1/chat/completions',
                'token': os.getenv('OPENROUTER_API_TOKEN'),
                'models': [
                    'google/gemini-2.0-flash-exp:free',
                    'mistralai/mistral-7b-instruct:free'
                ],
                'headers': {
                    'Authorization': f'Bearer {os.getenv("OPENROUTER_API_TOKEN")}',
                    'Content-Type': 'application/json',
                    'HTTP-Referer': 'https://github.com',
                    'X-Title': 'News NLP Trading AI'
                },
                'enabled': bool(os.getenv('OPENROUTER_API_TOKEN')),
                'priority': 2  # –†–µ–∑–µ—Ä–≤–Ω—ã–π
            }
        }
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        self.provider_priority = sorted(
            [p for p in self.providers.keys() if self.providers[p]['enabled']],
            key=lambda x: self.providers[x]['priority']
        )
        
        if not self.provider_priority:
            logger.warning("‚ö†Ô∏è –ù–∏ –æ–¥–∏–Ω –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–Ω—É–∂–µ–Ω GIGACHATAPI –∏–ª–∏ OPENROUTER_API_TOKEN)")
            logger.warning("‚ö†Ô∏è –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ SimpleAnalyzer")
        
        # –ò–Ω–¥–µ–∫—Å—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        self.model_indices = {provider: 0 for provider in self.provider_priority}
        
        # –ö—ç—à
        self.analysis_cache = {}
        self.cache_hits = 0
        self.cache_misses = 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'by_provider': {p: {'requests': 0, 'success': 0} for p in self.provider_priority},
            'cache_hits': 0,
            'cache_misses': 0
        }
        
        logger.info(f"ü§ñ –ì–∏–±—Ä–∏–¥–Ω—ã–π NLP-–¥–≤–∏–∂–æ–∫ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        if self.provider_priority:
            logger.info(f"üìä –î–æ—Å—Ç—É–ø–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã: {', '.join(self.provider_priority)}")
    
    def _create_cache_key(self, news_item: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –¥–ª—è –∫—ç—à–∞"""
        title = news_item.get('title', '')[:50].replace(' ', '_').lower()
        source = news_item.get('source', '')[:20].replace(' ', '_').lower()
        content_hash = hash(news_item.get('content', '')[:200]) % 10000
        return f"{source}_{title}_{content_hash}"
    
    def _create_prompt_for_provider(self, news_item: Dict, provider: str) -> Dict:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        
        title = news_item.get('title', '')
        description = news_item.get('description', '')
        content = news_item.get('content', '') or description
        source = news_item.get('source_name', news_item.get('source', 'Unknown'))
        
        if provider == 'gigachat':
            system_prompt = """–¢—ã ‚Äî —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–π –∞–Ω–∞–ª–∏—Ç–∏–∫ –°–±–µ—Ä–±–∞–Ω–∫–∞. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –Ω–æ–≤–æ—Å—Ç–∏ —Ä–æ—Å—Å–∏–π—Å–∫–æ–≥–æ —Ä—ã–Ω–∫–∞ –∞–∫—Ü–∏–π.
            
            –í–ê–ñ–ù–´–ô –ö–û–ù–¢–ï–ö–°–¢:
            1. –£—á–∏—Ç—ã–≤–∞–π –æ–±—â–∏–µ —Ä—ã–Ω–æ—á–Ω—ã–µ —É—Å–ª–æ–≤–∏—è. –ï—Å–ª–∏ —Ä—ã–Ω–æ–∫ —Å–µ–≥–æ–¥–Ω—è –≤ —Å–∏–ª—å–Ω–æ–º –ø–∞–¥–µ–Ω–∏–∏, –¥–∞–∂–µ –ø–æ–∑–∏—Ç–∏–≤–Ω–∞—è –Ω–æ–≤–æ—Å—Ç—å –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–Ω—ã–π —ç—Ñ—Ñ–µ–∫—Ç.
            2. –û–±—Ä–∞—â–∞–π –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –≤—Ä–µ–º—è –ø—É–±–ª–∏–∫–∞—Ü–∏–∏. –ù–æ–≤–æ—Å—Ç–∏ –≤ –Ω–µ—Ä–∞–±–æ—á–∏–µ —á–∞—Å—ã –º–æ–≥—É—Ç –∏–º–µ—Ç—å –∑–∞–ø–∞–∑–¥—ã–≤–∞—é—â—É—é —Ä–µ–∞–∫—Ü–∏—é.
            3. –†–∞–∑–ª–∏—á–∞–π —Ñ–∞–∫—Ç—ã –∏ –º–Ω–µ–Ω–∏—è/–ø—Ä–æ–≥–Ω–æ–∑—ã.
            
            –ò–ù–°–¢–†–£–ö–¶–ò–ò –î–õ–Ø –ê–ù–ê–õ–ò–ó–ê:
            1. –ù–∞–π–¥–∏ –≤—Å–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ä–æ—Å—Å–∏–π—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π –∏ –∏—Ö —Ç–∏–∫–µ—Ä–æ–≤ (–ø—Ä–∏–º–µ—Ä—ã: –°–±–µ—Ä–±–∞–Ω–∫ ‚Üí SBER, –ì–∞–∑–ø—Ä–æ–º ‚Üí GAZP, –õ—É–∫–æ–π–ª ‚Üí LKOH)
            2. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–∏–ø —Å–æ–±—ã—Ç–∏—è: earnings_report, dividend, merger_acquisition, regulatory, geopolitical, market_update, corporate_action, other
            3. –û—Ü–µ–Ω–∏ –≤–∞–∂–Ω–æ—Å—Ç—å (impact_score) –¥–ª—è —Ü–µ–Ω—ã –∞–∫—Ü–∏–∏: 1-3=–Ω–∏–∑–∫–∞—è, 4-6=—Å—Ä–µ–¥–Ω—è—è, 7-8=–≤—ã—Å–æ–∫–∞—è, 9-10=–∫—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è
            4. –û—Ü–µ–Ω–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ç—Ä–µ–π–¥–∏–Ω–≥–∞ (relevance_score): 1-100
            5. –û–ø—Ä–µ–¥–µ–ª–∏ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å: positive, negative, neutral, mixed
            6. –û–ø—Ä–µ–¥–µ–ª–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç –≤–ª–∏—è–Ω–∏—è: immediate (—Å–µ–≥–æ–¥–Ω—è), short_term (–Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π), medium_term (–Ω–µ–¥–µ–ª–∏), long_term (–º–µ—Å—è—Ü—ã+)
            7. –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ —Å—É—Ç—å (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –Ω–∞ —Ä—É—Å—Å–∫–æ–º)
            
            –í–û–ó–í–†–ê–©–ê–ô –¢–û–õ–¨–ö–û JSON –í –°–¢–†–û–ì–û–ú –§–û–†–ú–ê–¢–ï:
            {
                "analysis": {
                    "tickers": ["TICKER1", "TICKER2"],
                    "event_type": "—Ç–∏–ø_—Å–æ–±—ã—Ç–∏—è",
                    "impact_score": —á–∏—Å–ª–æ,
                    "relevance_score": —á–∏—Å–ª–æ,
                    "sentiment": "—Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å",
                    "horizon": "–≥–æ—Ä–∏–∑–æ–Ω—Ç",
                    "summary": "–∫—Ä–∞—Ç–∫–∞—è —Å—É—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º"
                }
            }
            
            –¢–û–õ–¨–ö–û JSON, –ë–ï–ó –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ì–û –¢–ï–ö–°–¢–ê!"""
            
        else:  # openrouter –∏ –¥—Ä—É–≥–∏–µ
            system_prompt = """You are a financial analyst AI. Analyze news and return strictly in JSON format.
            
            IMPORTANT CONTEXT:
            1. Consider overall market conditions. Even positive news may have limited effect in a bearish market.
            2. Note the publication time. News published outside market hours may have delayed reaction.
            3. Distinguish between facts and opinions/forecasts.
            
            ANALYSIS INSTRUCTIONS:
            1. Extract all company mentions and their tickers
            2. Determine event type: earnings_report, dividend, merger_acquisition, regulatory, geopolitical, market_update, corporate_action, other
            3. Rate importance (impact_score) for stock price: 1-10
            4. Rate relevance for trading (relevance_score): 1-100
            5. Determine sentiment: positive, negative, neutral, mixed
            6. Determine impact horizon: immediate (today), short_term (few days), medium_term (weeks), long_term (months+)
            7. Provide brief summary
            
            RETURN ONLY JSON IN THIS EXACT FORMAT:
            {
                "analysis": {
                    "tickers": ["TICKER1", "TICKER2"],
                    "event_type": "event_type",
                    "impact_score": number,
                    "relevance_score": number,
                    "sentiment": "sentiment",
                    "horizon": "horizon",
                    "summary": "brief summary"
                }
            }
            
            ONLY JSON, NO OTHER TEXT!"""
        
        # –í—ã–±–∏—Ä–∞–µ–º –º–æ–¥–µ–ª—å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
        model_idx = self.model_indices[provider]
        models = self.providers[provider]['models']
        model = models[model_idx % len(models)]
        
        return {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"–ò—Å—Ç–æ—á–Ω–∏–∫: {source}\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: {title}\n–¢–µ–∫—Å—Ç: {content[:1200]}"}
            ],
            "temperature": 0.1,
            "max_tokens": 600
        }
    
    def _switch_to_next_model(self, provider: str):
        """–ü–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ –Ω–∞ —Å–ª–µ–¥—É—é—â—É—é –º–æ–¥–µ–ª—å —É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        models = self.providers[provider]['models']
        if len(models) > 1:
            old_idx = self.model_indices[provider]
            self.model_indices[provider] = (old_idx + 1) % len(models)
            old_model = models[old_idx]
            new_model = models[self.model_indices[provider]]
            logger.info(f"üîÑ {provider}: —Å–º–µ–Ω–∞ –º–æ–¥–µ–ª–∏ {old_model} ‚Üí {new_model}")
    
    async def analyze_news(self, news_item: Dict) -> Optional[Dict]:
        """–ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        
        self.stats['total_requests'] += 1
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫—ç—à–∞
        cache_key = self._create_cache_key(news_item)
        if cache_key in self.analysis_cache:
            self.stats['cache_hits'] += 1
            self.cache_hits += 1
            logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É—é –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ (hits: {self.cache_hits})")
            return self.analysis_cache[cache_key]
        
        self.stats['cache_misses'] += 1
        self.cache_misses += 1
        news_title = news_item.get('title', '')[:50]
        logger.info(f"üß† –ê–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–∏ #{self.stats['total_requests']}: {news_title}...")
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None
        if not self.provider_priority:
            logger.warning("‚ö†Ô∏è –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ò–ò-–ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑")
            return None
        
        # –ü—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç—É
        for provider in self.provider_priority:
            if not self.providers[provider]['enabled']:
                continue
            
            logger.info(f"üì° –ü—Ä–æ–±—É—é –ø—Ä–æ–≤–∞–π–¥–µ—Ä: {provider.upper()}")
            self.stats['by_provider'][provider]['requests'] += 1
            
            # –ü—Ä–æ–±—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
            max_retries = min(2, len(self.providers[provider]['models']))
            
            for attempt in range(max_retries):
                try:
                    logger.info(f"   üì® –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries}")
                    
                    # –°–æ–∑–¥–∞–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞
                    prompt_data = self._create_prompt_for_provider(news_item, provider)
                    
                    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º httpx –¢–û–õ–¨–ö–û –ó–î–ï–°–¨, –∫–æ–≥–¥–∞ –æ–Ω –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–µ–Ω
                    import httpx
                    
                    # –û–°–ù–û–í–ù–û–ï –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –æ—Ç–∫–ª—é—á–∞–µ–º SSL –ø—Ä–æ–≤–µ—Ä–∫—É –¢–û–õ–¨–ö–û –¥–ª—è GigaChat
                    if provider == 'gigachat':
                        # –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É SSL –¥–ª—è GigaChat –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–æ–º
                        async with httpx.AsyncClient(timeout=30.0, verify=False) as client:
                            response = await client.post(
                                url=self.providers[provider]['url'],
                                headers=self.providers[provider]['headers'],
                                json=prompt_data
                            )
                    else:
                        # –î–ª—è –¥—Ä—É–≥–∏—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –æ—Å—Ç–∞–≤–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É SSL
                        async with httpx.AsyncClient(timeout=30.0) as client:
                            response = await client.post(
                                url=self.providers[provider]['url'],
                                headers=self.providers[provider]['headers'],
                                json=prompt_data
                            )
                    
                    logger.info(f"   üì• –û—Ç–≤–µ—Ç {provider}: —Å—Ç–∞—Ç—É—Å {response.status_code}")
                    
                    if response.status_code == 200:
                        result = response.json()
                        ai_response = result.get("choices", [{}])[0].get("message", {}).get("content", "")
                        
                        if not ai_response:
                            logger.warning(f"   ‚ö†Ô∏è {provider}: –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç")
                            continue
                        
                        # –ü–∞—Ä—Å–∏–Ω–≥ JSON –æ—Ç–≤–µ—Ç–∞
                        analysis_result = self._parse_ai_response(ai_response, news_item, provider)
                        
                        if analysis_result:
                            self.stats['successful_requests'] += 1
                            self.stats['by_provider'][provider]['success'] += 1
                            
                            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                            self.analysis_cache[cache_key] = analysis_result
                            if len(self.analysis_cache) > 100:
                                oldest = next(iter(self.analysis_cache))
                                del self.analysis_cache[oldest]
                            
                            logger.info(f"   ‚úÖ {provider}: —É—Å–ø–µ—à–Ω—ã–π –∞–Ω–∞–ª–∏–∑")
                            return analysis_result
                        else:
                            logger.warning(f"   ‚ö†Ô∏è {provider}: –Ω–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –æ—Ç–≤–µ—Ç")
                    
                    elif response.status_code in [400, 404]:
                        error_data = response.json()
                        error_msg = error_data.get('error', {}).get('message', 'Unknown error')[:100]
                        logger.warning(f"   ‚ö†Ô∏è {provider}: –æ—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ - {error_msg}")
                        
                        if attempt < max_retries - 1:
                            self._switch_to_next_model(provider)
                            await asyncio.sleep(1)
                            continue
                    
                    elif response.status_code == 429:
                        logger.warning(f"   ‚ö†Ô∏è {provider}: rate limit")
                        break  # –ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É
                    
                    elif response.status_code == 401:
                        logger.error(f"   ‚ùå {provider}: –æ—à–∏–±–∫–∞ –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ (–Ω–µ–≤–µ—Ä–Ω—ã–π —Ç–æ–∫–µ–Ω?)")
                        break
                    
                    else:
                        logger.warning(f"   ‚ö†Ô∏è {provider}: HTTP {response.status_code}")
                        break
                        
                except httpx.TimeoutException:
                    logger.error(f"   ‚è∞ {provider}: —Ç–∞–π–º–∞—É—Ç")
                    if attempt < max_retries - 1:
                        self._switch_to_next_model(provider)
                        await asyncio.sleep(2)
                        continue
                    break
                    
                except Exception as e:
                    logger.error(f"   ‚ùå {provider}: –æ—à–∏–±–∫–∞ - {str(e)[:100]}")
                    break
            
            # –ù–µ–±–æ–ª—å—à–∞—è –ø–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–º
            await asyncio.sleep(0.5)
        
        logger.error(f"‚ùå –í—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–∏")
        return None
    
    def _parse_ai_response(self, response: str, news_item: Dict, provider: str) -> Optional[Dict]:
        """–ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞ –ò–ò"""
        try:
            # –û—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞
            response = response.strip()
            
            # –£–¥–∞–ª—è–µ–º markdown –∫–æ–¥–æ–≤—ã–µ –±–ª–æ–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()
            
            # –ò—â–µ–º JSON
            start_idx = response.find('{')
            end_idx = response.rfind('}') + 1
            
            if start_idx == -1 or end_idx == 0:
                logger.warning(f"   ‚ö†Ô∏è {provider}: –Ω–µ –Ω–∞–π–¥–µ–Ω JSON –≤ –æ—Ç–≤–µ—Ç–µ")
                return None
            
            json_str = response[start_idx:end_idx]
            data = json.loads(json_str)
            
            analysis_data = data.get("analysis", {})
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–æ–ª–µ–π
            required_fields = ['tickers', 'event_type', 'impact_score', 'relevance_score']
            if not all(field in analysis_data for field in required_fields):
                logger.warning(f"   ‚ö†Ô∏è {provider}: –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è")
                return None
            
            # –°–æ–∑–¥–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞
            result = {
                'news_id': news_item.get('id', ''),
                'news_title': news_item.get('title', ''),
                'news_source': news_item.get('source', ''),
                'news_url': news_item.get('url', ''),
                'analysis_timestamp': datetime.now().isoformat(),
                
                # –ê–Ω–∞–ª–∏–∑ –ò–ò
                'tickers': analysis_data.get('tickers', []),
                'event_type': analysis_data.get('event_type', 'other'),
                'impact_score': int(analysis_data.get('impact_score', 1)),
                'relevance_score': int(analysis_data.get('relevance_score', 30)),
                'sentiment': analysis_data.get('sentiment', 'neutral'),
                'horizon': analysis_data.get('horizon', 'short_term'),
                'summary': analysis_data.get('summary', ''),
                
                # –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                'ai_provider': provider,
                'ai_model': self.providers[provider]['models'][self.model_indices[provider]],
                'confidence': min(1.0, analysis_data.get('relevance_score', 30) / 100.0)
            }
            
            # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            tickers_str = ', '.join(result['tickers']) if result['tickers'] else '–ù–ï–¢ –¢–ò–ö–ï–†–û–í'
            logger.info(f"   üìä {provider}: {tickers_str} | Impact: {result['impact_score']}/10")
            
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"   ‚ùå {provider}: –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON - {str(e)[:50]}")
            logger.debug(f"   üí¨ –û—Ç–≤–µ—Ç: {response[:200]}")
            return None
        except Exception as e:
            logger.error(f"   ‚ùå {provider}: –æ—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ - {str(e)[:50]}")
            return None
    
    def get_current_provider(self) -> str:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ç–µ–∫—É—â–µ–≥–æ –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        return self.provider_priority[0] if self.provider_priority else "simple"
    
    def get_stats(self) -> Dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ä–∞–±–æ—Ç—ã NLP-–¥–≤–∏–∂–∫–∞"""
        success_rate = (self.stats['successful_requests'] / self.stats['total_requests'] * 100) if self.stats['total_requests'] > 0 else 0
        cache_hit_rate = (self.stats['cache_hits'] / (self.stats['cache_hits'] + self.stats['cache_misses']) * 100) if (self.stats['cache_hits'] + self.stats['cache_misses']) > 0 else 0
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º
        provider_stats = {}
        for provider in self.providers:
            req = self.stats['by_provider'].get(provider, {}).get('requests', 0)
            succ = self.stats['by_provider'].get(provider, {}).get('success', 0)
            rate = (succ / req * 100) if req > 0 else 0
            provider_stats[provider] = {
                'requests': req,
                'success': succ,
                'success_rate': round(rate, 1),
                'enabled': self.providers[provider]['enabled'],
                'models': len(self.providers[provider]['models'])
            }
        
        return {
            'total_requests': self.stats['total_requests'],
            'successful_requests': self.stats['successful_requests'],
            'success_rate': round(success_rate, 1),
            'cache_hits': self.stats['cache_hits'],
            'cache_misses': self.stats['cache_misses'],
            'cache_hit_rate': round(cache_hit_rate, 1),
            'current_provider': self.get_current_provider(),
            'providers': provider_stats
        }

# signal_pipeline.py - –£–ü–†–û–©–ï–ù–ù–´–ô –ü–ê–ô–ü–õ–ê–ô–ù –° GIGACHAT
import logging
import asyncio
from datetime import datetime
from typing import Dict, List, Optional
import hashlib

logger = logging.getLogger(__name__)

class SignalPipeline:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∫–æ–Ω–≤–µ–π–µ—Ä –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å GigaChat"""
    
    def __init__(self, nlp_engine, finam_verifier, risk_manager, enhanced_analyzer, news_prefilter):
        self.nlp_engine = nlp_engine
        self.finam_verifier = finam_verifier
        self.risk_manager = risk_manager
        self.enhanced_analyzer = enhanced_analyzer
        self.news_prefilter = news_prefilter
        
        # –ö—ç—à –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è
        self.news_cache = {}
        self.cache_ttl = 300  # 5 –º–∏–Ω—É—Ç
        
        self.stats = {
            'total_news': 0,
            'filtered_news': 0,
            'gigachat_requests': 0,
            'gigachat_success': 0,
            'verification_passed': 0,
            'signals_generated': 0,
            'pipeline_start': datetime.now().isoformat()
        }
        
        logger.info("üöÄ SignalPipeline –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω (GigaChat-centric)")
        logger.info("   –≠—Ç–∞–ø—ã: PreFilter ‚Üí GigaChat ‚Üí Finam ‚Üí RiskManager")
    
    async def process_news_batch(self, news_list: List[Dict]) -> List[Dict]:
        """–ü–∞–∫–µ—Ç–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π"""
        
        self.stats['total_news'] += len(news_list)
        
        logger.info(f"üìä –û–±—Ä–∞–±–æ—Ç–∫–∞ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π —á–µ—Ä–µ–∑ GigaChat...")
        
        signals = []
        processed = 0
        
        # –ü–û–°–õ–ï–î–û–í–ê–¢–ï–õ–¨–ù–ê–Ø –æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        for news_item in news_list:
            try:
                signal = await self._process_single_news(news_item)
                if signal:
                    signals.append(signal)
                
                processed += 1
                
                # –ü–∞—É–∑–∞ –∫–∞–∂–¥—ã–µ 5 –Ω–æ–≤–æ—Å—Ç–µ–π
                if processed % 5 == 0:
                    await asyncio.sleep(1)
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏: {str(e)[:100]}")
                continue
        
        self.stats['signals_generated'] += len(signals)
        
        logger.info(f"üìä –ò—Ç–æ–≥–∏: {len(signals)} —Å–∏–≥–Ω–∞–ª–æ–≤ –∏–∑ {len(news_list)} –Ω–æ–≤–æ—Å—Ç–µ–π")
        logger.info(f"   –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {(len(signals)/max(1, len(news_list))*100):.1f}%")
        
        return signals
    
    async def _process_single_news(self, news_item: Dict) -> Optional[Dict]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–π –Ω–æ–≤–æ—Å—Ç–∏"""
        
        # 1. –ö–≠–®–ò–†–û–í–ê–ù–ò–ï (–ø—Ä–æ–≤–µ—Ä–∫–∞ –¥—É–±–ª–µ–π)
        news_hash = self._create_news_hash(news_item)
        if news_hash in self.news_cache:
            cache_time, cache_result = self.news_cache[news_hash]
            if (datetime.now().timestamp() - cache_time) < self.cache_ttl:
                if cache_result:
                    logger.debug(f"üîÑ –ö—ç—à-–ø–æ–ø–∞–¥–∞–Ω–∏–µ: {news_item.get('title', '')[:50]}")
                    return cache_result
                return None
        
        # 2. –ü–†–ï-–§–ò–õ–¨–¢–†–ê–¶–ò–Ø
        if not self.news_prefilter.is_tradable(news_item):
            self.stats['filtered_news'] += 1
            logger.debug(f"   ‚ùå PreFilter: {news_item.get('title', '')[:50]}")
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à –∫–∞–∫ "–Ω–µ —Ç–æ—Ä–≥—É–µ–º—ã–π"
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        # 3. GIGACHAT –ê–ù–ê–õ–ò–ó
        self.stats['gigachat_requests'] += 1
        logger.debug(f"   üì° GigaChat: {news_item.get('title', '')[:60]}")
        
        nlp_analysis = await self.nlp_engine.analyze_news(news_item)
        
        if not nlp_analysis:
            logger.debug(f"   ‚ùå GigaChat –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª")
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        self.stats['gigachat_success'] += 1
        
        # –ï—Å–ª–∏ GigaChat —Å–∫–∞–∑–∞–ª "–Ω–µ —Ç–æ—Ä–≥—É–µ–º—ã–π"
        if not nlp_analysis.get('is_tradable', True):
            logger.debug(f"   ‚ö†Ô∏è GigaChat: –Ω–µ —Ç–æ—Ä–≥–æ–≤—ã–π —Å–∏–≥–Ω–∞–ª")
            self.news_cache[news_hash] = (datetime.now().timestamp(), None)
            return None
        
        # 4. –í–ï–†–ò–§–ò–ö–ê–¶–ò–Ø –ß–ï–†–ï–ó FINAM
        verification = await self.finam_verifier.verify_signal(nlp_analysis)
        
        if not verification['valid']:
            logger.debug(f"   ‚ùå Finam: {verification.get('reason', '')}")
            return None
        
        self.stats['verification_passed'] += 1
        
        # 5. –ü–û–õ–£–ß–ï–ù–ò–ï –¶–ï–ù
        tickers = verification.get('tickers', [])
        current_prices = {}
        
        for ticker in tickers:
            price = await self.finam_verifier.get_current_prices([ticker])
            if ticker in price:
                current_prices[ticker] = price[ticker]
        
        if not current_prices:
            logger.debug(f"   ‚ùå –ù–µ—Ç —Ü–µ–Ω –¥–ª—è —Ç–∏–∫–µ—Ä–æ–≤")
            return None
        
        # 6. RISK MANAGER (–ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–∏–≥–Ω–∞–ª–∞)
        signal = self.risk_manager.prepare_signal(
            analysis=nlp_analysis,
            verification=verification,
            current_prices=current_prices
        )
        
        if signal:
            # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
            signal.update({
                'pipeline_version': 'gigachat_v1',
                'news_hash': news_hash,
                'processing_timestamp': datetime.now().isoformat(),
                'nlp_provider': 'gigachat',
                'verification_source': 'finam'
            })
            
            logger.info(f"‚úÖ –°–ò–ì–ù–ê–õ: {signal['action']} {signal['ticker']} (impact={signal['impact_score']})")
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
            self.news_cache[news_hash] = (datetime.now().timestamp(), signal)
        
        return signal
    
    def _create_news_hash(self, news_item: Dict) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ö—ç—à–∞ –Ω–æ–≤–æ—Å—Ç–∏ –¥–ª—è –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏—è"""
        title = news_item.get('title', '')
        content = news_item.get('content', '') or news_item.get('description', '')
        source = news_item.get('source', '')
        
        text = f"{title[:100]}|{content[:200]}|{source}"
        return hashlib.md5(text.encode()).hexdigest()[:16]
    
    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏"""
        total = self.stats['total_news']
        gigachat_req = self.stats['gigachat_requests']
        gigachat_succ = self.stats['gigachat_success']
        signals = self.stats['signals_generated']
        
        if total > 0:
            filter_rate = (self.stats['filtered_news'] / total) * 100
            if gigachat_req > 0:
                gigachat_success_rate = (gigachat_succ / gigachat_req) * 100
            else:
                gigachat_success_rate = 0
            signal_rate = (signals / total) * 100
        else:
            filter_rate = gigachat_success_rate = signal_rate = 0
        
        return {
            **self.stats,
            'filter_rate_percent': round(filter_rate, 1),
            'gigachat_success_rate': round(gigachat_success_rate, 1),
            'signal_rate_percent': round(signal_rate, 1),
            'news_cache_size': len(self.news_cache),
            'current_time': datetime.now().isoformat(),
            'processing_mode': 'gigachat_sequential'
        }
